# -*- coding: utf-8 -*-
"""evaluate_Faster R-CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eLxfwUVRHB87FxS_e5V4oIw5HQXIFTpe
"""

# Validation
# Dataset class and collate_fn imported from datasets/kitti.py
from dataset.kitti import FilteredKITTIDataset, collate_fn

val_dataset = FilteredKITTIDataset(
    '/content/drive/MyDrive/faster r-cnn/train/images',
    '/content/drive/MyDrive/faster r-cnn/train/labels',
    'val.txt'
)

val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)

# Validation (metrics)
import torch
from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn
from engine import evaluate
from coco_utils import convert_to_coco_api
from coco_eval import CocoEvaluator

# Load the model
model = fasterrcnn_resnet50_fpn(pretrained=False, num_classes=2)  # background + car
model.load_state_dict(torch.load("/content/fasterrcnn_best1.pth"))
model.eval().cuda()

# Validation DataLoader

# Run evaluation
evaluate(model, val_loader, device=torch.device('cuda'))

# Validation visualization
import matplotlib.pyplot as plt
import torchvision.transforms.functional as F

def visualize_prediction(image, prediction, threshold=0.9):
    image = image.permute(1, 2, 0).cpu().numpy()
    plt.imshow(image)

    boxes = prediction['boxes'].cpu().numpy()
    scores = prediction['scores'].cpu().numpy()
    labels = prediction['labels'].cpu().numpy()

    for box, score, label in zip(boxes, scores, labels):
        if score > threshold:
            x1, y1, x2, y2 = box
            plt.gca().add_patch(plt.Rectangle((x1, y1), x2-x1, y2-y1,
                                              fill=False, edgecolor='r', linewidth=1))
            plt.gca().text(x1, y1, f'{label}: {score:.2}', color='white',
                           bbox=dict(facecolor='blue', alpha=0.5))
    plt.axis('off')
    plt.show()

# Visualize a few examples
for images, _ in val_loader:
    with torch.no_grad():
        images_cuda = [img.to(device) for img in images]
        preds = model(images_cuda)
    for img, pred in zip(images, preds):
        visualize_prediction(img, pred)
    break  # remove break to visualize more

# Validation (Visualize & save)
import os
import matplotlib.pyplot as plt
import torchvision.transforms.functional as F

save_dir = '/content/result_faster_rcnn_conf_0.9'
os.makedirs(save_dir, exist_ok=True)

def visualize_and_save(image, prediction, idx, threshold=0.9):
    image_np = image.permute(1, 2, 0).cpu().numpy()
    plt.figure(figsize=(10,10))
    plt.imshow(image_np)

    boxes = prediction['boxes'].cpu().numpy()
    scores = prediction['scores'].cpu().numpy()
    labels = prediction['labels'].cpu().numpy()

    for box, score, label in zip(boxes, scores, labels):
        if score > threshold:
            x1, y1, x2, y2 = box
            plt.gca().add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1,
                                              fill=False, edgecolor='r', linewidth=2))
            plt.gca().text(x1, y1, f'{label}: {score:.2f}', color='white',
                           bbox=dict(facecolor='blue', alpha=0.5))

    plt.axis('off')
    save_path = os.path.join(save_dir, f'pred_{idx}.png')
    plt.savefig(save_path, bbox_inches='tight')
    plt.close()

# Run inference and save visualizations for the val_loader
idx = 0
model.eval()
with torch.no_grad():
    for images, _ in val_loader:
        images_cuda = [img.to(device) for img in images]
        preds = model(images_cuda)
        for img, pred in zip(images, preds):
            visualize_and_save(img, pred, idx)
            idx += 1

print(f"Saved {idx} prediction images to {save_dir}")

from google.colab import files

# Zip the folder first
import shutil
shutil.make_archive('/content/result_faster_rcnn_conf_0.9', 'zip', '/content/result_faster_rcnn_conf_0.9')

# Download the zip file directly
files.download('/content/result_faster_rcnn_conf_0.9.zip')