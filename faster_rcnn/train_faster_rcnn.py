# -*- coding: utf-8 -*-
"""train_faster_rcnn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yj4loHlK6zcMRYUpzY6nGJlvigoHby5O
"""

# Dataset class and collate_fn imported from datasets/kitti.py
from dataset.kitti import FilteredKITTIDataset, collate_fn

# Step 5: Create dataset & dataloader for train & val

train_dataset = FilteredKITTIDataset(
    '/content/drive/MyDrive/faster r-cnn/train/images',
    '/content/drive/MyDrive/faster r-cnn/train/labels',
    'train.txt',
    #transforms = None
)

val_dataset = FilteredKITTIDataset(
    '/content/drive/MyDrive/faster r-cnn/train/images',
    '/content/drive/MyDrive/faster r-cnn/train/labels',
    'val.txt'
)

train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)
val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)

# Step 6: Load model, set number of classes, & change the layer accordingly
from torchvision.models.detection import fasterrcnn_resnet50_fpn
import torchvision
import torch
import torch.optim as optim

# Load pre-trained Faster R-CNN
model = fasterrcnn_resnet50_fpn(pretrained=True)
num_classes = 2  # 1 class ('Car') + background
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)

# Move model to GPU or CPU
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# Set optimizer
params = [p for p in model.parameters() if p.requires_grad]
optimizer = optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)

# Learning rate scheduler
from torch.optim.lr_scheduler import StepLR
lr_scheduler = StepLR(optimizer, step_size=10, gamma=0.1)

# Training loop with best model saving
best_val_loss = float('inf')
best_model_path = "fasterrcnn_best1.pth"
num_epochs = 40

for epoch in range(num_epochs):
    # --- Training ---
    model.train() # Input: images + targets, Output: loss_dict for torchvision
    train_loss = 0.0
    # Initialize at start of epoch
    loss_comp_sum = {
        'loss_classifier': 0.0,
        'loss_box_reg': 0.0,
        'loss_objectness': 0.0,
        'loss_rpn_box_reg': 0.0
    }
    for imgs, targets in train_loader:
        imgs = [img.to(device) for img in imgs]
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

        loss_dict = model(imgs, targets)
        losses = sum(loss for loss in loss_dict.values())
        for k in loss_dict:
            loss_comp_sum[k] += loss_dict[k].item()
        #for k, v in loss_dict.items():
          #  print(f"Epoch [{epoch+1}] - {k}: {v.item():.4f}") # losses like loss_classifier + loss_box_reg + loss_objectness + loss_rpn_box_reg

        optimizer.zero_grad()
        losses.backward()
        optimizer.step()

        train_loss += losses.item()

    avg_train_loss = train_loss / len(train_loader)

    # --- Validation ---
    # model.eval() # Input: images only (targets = None) Output: predictions
    model.train()  # NOTE: Needed to compute loss in torchvision models, switch back to train mode to compute loss
    val_loss = 0.0
    with torch.no_grad():
        for imgs, targets in val_loader:
            imgs = [img.to(device) for img in imgs]
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

            loss_dict = model(imgs, targets)
            losses = sum(loss for loss in loss_dict.values())
            val_loss += losses.item()
    model.eval()  # return to eval mode after validation for safety and good practice.

    avg_val_loss = val_loss / len(val_loader)

    # Update the learning rate
    lr_scheduler.step()
    print(f"Current LR: {optimizer.param_groups[0]['lr']:.6f}")

    # After epoch loop
    num_batches = len(train_loader)
    for k in loss_comp_sum:
        print(f"Epoch [{epoch+1}] - Avg {k}: {loss_comp_sum[k]/num_batches:.4f}")

    # Save best model
    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        torch.save(model.state_dict(), best_model_path)
        print(f"Saved best model at epoch {epoch+1} with val loss {best_val_loss:.4f}")

    print(f"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}")

    # Optional: save model each epoch
    # torch.save(model.state_dict(), f'fasterrcnn_epoch{epoch+1}.pth')  # ← uncomment if you want per-epoch checkpoints



# Validation (metrics)
import torch
from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn
from engine import evaluate
from coco_utils import convert_to_coco_api
from coco_eval import CocoEvaluator

# Load the model
model = fasterrcnn_resnet50_fpn(pretrained=False, num_classes=2)  # background + car
model.load_state_dict(torch.load("/content/fasterrcnn_best1.pth"))
model.eval().cuda()

# Validation DataLoader

# Run evaluation
evaluate(model, val_loader, device=torch.device('cuda'))

# Validation visualization
import matplotlib.pyplot as plt
import torchvision.transforms.functional as F

def visualize_prediction(image, prediction, threshold=0.9):
    image = image.permute(1, 2, 0).cpu().numpy()
    plt.imshow(image)

    boxes = prediction['boxes'].cpu().numpy()
    scores = prediction['scores'].cpu().numpy()
    labels = prediction['labels'].cpu().numpy()

    for box, score, label in zip(boxes, scores, labels):
        if score > threshold:
            x1, y1, x2, y2 = box
            plt.gca().add_patch(plt.Rectangle((x1, y1), x2-x1, y2-y1,
                                              fill=False, edgecolor='r', linewidth=1))
            plt.gca().text(x1, y1, f'{label}: {score:.2}', color='white',
                           bbox=dict(facecolor='blue', alpha=0.5))
    plt.axis('off')
    plt.show()

# Visualize a few examples
for images, _ in val_loader:
    with torch.no_grad():
        images_cuda = [img.to(device) for img in images]
        preds = model(images_cuda)
    for img, pred in zip(images, preds):
        visualize_prediction(img, pred)
    break  # remove break to visualize more

# Validation (Visualize & save)
import os
import matplotlib.pyplot as plt
import torchvision.transforms.functional as F

save_dir = '/content/result_faster_rcnn_conf_0.9'
os.makedirs(save_dir, exist_ok=True)

def visualize_and_save(image, prediction, idx, threshold=0.9):
    image_np = image.permute(1, 2, 0).cpu().numpy()
    plt.figure(figsize=(10,10))
    plt.imshow(image_np)

    boxes = prediction['boxes'].cpu().numpy()
    scores = prediction['scores'].cpu().numpy()
    labels = prediction['labels'].cpu().numpy()

    for box, score, label in zip(boxes, scores, labels):
        if score > threshold:
            x1, y1, x2, y2 = box
            plt.gca().add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1,
                                              fill=False, edgecolor='r', linewidth=2))
            plt.gca().text(x1, y1, f'{label}: {score:.2f}', color='white',
                           bbox=dict(facecolor='blue', alpha=0.5))

    plt.axis('off')
    save_path = os.path.join(save_dir, f'pred_{idx}.png')
    plt.savefig(save_path, bbox_inches='tight')
    plt.close()

# Run inference and save visualizations for the val_loader
idx = 0
model.eval()
with torch.no_grad():
    for images, _ in val_loader:
        images_cuda = [img.to(device) for img in images]
        preds = model(images_cuda)
        for img, pred in zip(images, preds):
            visualize_and_save(img, pred, idx)
            idx += 1

print(f"Saved {idx} prediction images to {save_dir}")

from google.colab import files

# Zip the folder first
import shutil
shutil.make_archive('/content/result_faster_rcnn_conf_0.9', 'zip', '/content/result_faster_rcnn_conf_0.9')

# Download the zip file directly
files.download('/content/result_faster_rcnn_conf_0.9.zip')